<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="2017.6 CS硕士毕业,目前就职于中国电信IT研发中心大数据部门"><title>spark submit参数说明与调优 | CaoK' Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">spark submit参数说明与调优</h1><a id="logo" href="/.">CaoK' Blog</a><p class="description">But you didn't</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">spark submit参数说明与调优</h1><div class="post-meta">Aug 8, 2017</div><div class="post-content"><p>来电信一段时间了，提交了不少spark程序，这次深入了解下spark submit参数。<br>本文参考了《spark快速大数据分析》（神书推荐)<br>demo:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">inpath=<span class="string">"hdfs://ns/user/wenting/TeleCRMData/*.gz"</span></div><div class="line">inpathTele=<span class="string">"hdfs://ns/user/caokai/AppWithTimePeriod/20170705/*.gz"</span></div><div class="line">output=<span class="string">"hdfs://ns/user/caokai/AgeModelData003"</span></div><div class="line">spark-submit  --master  yarn-cluster  --class  DealRawData.JoinCRMAPP_test001  --num-executors 30 --driver-memory 2g --executor-memory 8g --executor-cores 2 DealRawDataForY.jar <span class="variable">$&#123;inpath&#125;</span> <span class="variable">$&#123;inpathTele&#125;</span> <span class="variable">$&#123;output&#125;</span></div></pre></td></tr></table></figure></p>
<p>spark submit参数介绍</p>
<a id="more"></a>
<p>可以通过spark-submit –help或者spark-shell –help来查看这些参数。<br>使用格式:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">./bin/spark-submit \</div><div class="line">  --class &lt;main-class&gt; \</div><div class="line">  --master &lt;master-url&gt; \</div><div class="line">  --deploy-mode &lt;deploy-mode&gt; \</div><div class="line">  --conf &lt;key&gt;=&lt;value&gt; \</div><div class="line">  ... <span class="comment"># other options</span></div><div class="line">  &lt;application-jar&gt; \</div><div class="line">  [application-arguments]</div></pre></td></tr></table></figure></p>
<p>参数名                格式                参数说明<br>–master                MASTER_URL        如spark://host:port, mesos://host:port, yarn,  yarn-cluster,yarn-client, local<br>–deploy-mode            DEPLOY_MODE        Client或者master，默认是client<br>–class                CLASS_NAME        应用程序的主类<br>–name                NAME            应用程序的名称<br>–jars                JARS                逗号分隔的本地jar包，包含在driver和executor的classpath下<br>–packages                                包含在driver和executor的classpath下的jar包逗号分隔的”groupId:artifactId：version”列表<br>–exclude-packages                        用逗号分隔的”groupId:artifactId”列表<br>–repositories                            逗号分隔的远程仓库<br>–py-files                PY_FILES            逗号分隔的”.zip”,”.egg”或者“.py”文件，这些文件放在python app的PYTHONPATH下面<br>–files                FILES            逗号分隔的文件，这些文件放在每个executor的工作目录下面<br>–conf                PROP=VALUE        固定的spark配置属性，默认是conf/spark-defaults.conf<br>–properties-file            FILE                加载额外属性的文件<br>–driver-memory            MEM                Driver内存，默认1G<br>–driver-java-options                        传给driver的额外的Java选项<br>–driver-library-path                        传给driver的额外的库路径<br>–driver-class-path                        传给driver的额外的类路径<br>–executor-memory        MEM                每个executor的内存，默认是1G<br>–proxy-user            NAME            模拟提交应用程序的用户<br>–driver-cores            NUM                Driver的核数，默认是1。这个参数仅仅在standalone集群deploy模式下使用<br>–supervise                            Driver失败时，重启driver。在mesos或者standalone下使用<br>–verbose                                打印debug信息<br>–total-executor-cores        NUM                所有executor总共的核数。仅仅在mesos或者standalone下使用<br>–executor-core            NUM                每个executor的核数。在yarn或者standalone下使用<br>–driver-cores            NUM                Driver的核数，默认是1。在yarn集群模式下使用<br>–queue                QUEUE_NAME        队列名称。在yarn下使用<br>–num-executors        NUM                启动的executor数量。默认为2。在yarn下使用<br>试例：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Run application locally on 8 cores(本地模式8核)</span></div><div class="line">./bin/spark-submit \</div><div class="line">  --class org.apache.spark.examples.SparkPi \</div><div class="line">  --master <span class="built_in">local</span>[8] \</div><div class="line">  /path/to/examples.jar \</div><div class="line">  100</div><div class="line"><span class="comment"># Run on a Spark standalone cluster in client deploy mode(standalone client模式)</span></div><div class="line">./bin/spark-submit \</div><div class="line">  --class org.apache.spark.examples.SparkPi \</div><div class="line">  --master spark://207.184.161.138:7077 \</div><div class="line">  --executor-memory 20G \</div><div class="line">  --total-executor-cores 100 \</div><div class="line">  /path/to/examples.jar \</div><div class="line">  1000</div><div class="line"><span class="comment"># Run on a Spark standalone cluster in cluster deploy mode with supervise(standalone cluster模式使用supervise)</span></div><div class="line">./bin/spark-submit \</div><div class="line">  --class org.apache.spark.examples.SparkPi \</div><div class="line">  --master spark://207.184.161.138:7077 \</div><div class="line">  --deploy-mode cluster \</div><div class="line">  --supervise \</div><div class="line">  --executor-memory 20G \</div><div class="line">  --total-executor-cores 100 \</div><div class="line">  /path/to/examples.jar \</div><div class="line">  1000</div><div class="line"><span class="comment"># Run on a YARN cluster(YARN cluster模式)</span></div><div class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=XXX</div><div class="line">./bin/spark-submit \</div><div class="line">  --class org.apache.spark.examples.SparkPi \</div><div class="line">  --master yarn \</div><div class="line">  --deploy-mode cluster \  <span class="comment"># can be client for client mode</span></div><div class="line">  --executor-memory 20G \</div><div class="line">  --num-executors 50 \</div><div class="line">  /path/to/examples.jar \</div><div class="line">  1000</div><div class="line"><span class="comment"># Run on a Mesos cluster in cluster deploy mode with supervise(Mesos cluster模式使用supervise)</span></div><div class="line">./bin/spark-submit \</div><div class="line">  --class org.apache.spark.examples.SparkPi \</div><div class="line">  --master mesos://207.184.161.138:7077 \</div><div class="line">  --deploy-mode cluster \</div><div class="line">  --supervise \</div><div class="line">  --executor-memory 20G \</div><div class="line">  --total-executor-cores 100 \</div><div class="line">  http://path/to/examples.jar \</div><div class="line">  1000</div></pre></td></tr></table></figure></p>
<p>在公司使用最多的是spark on yarn模式，下面主要讲<strong>spark on yarn</strong><br><strong><em>资源参数调优</em></strong><br>所谓的Spark资源参数调优，其实主要就是对Spark运行过程中各个使用资源的地方，通过调节各种参数，来优化资源使用的效率，从而提升Spark作业的执行性能。<br>以下参数就是Spark中主要的资源参数，每个参数都对应着作业运行原理中的某个部分，同时也给出了一个调优的参考值。<br>num-executors<br>参数说明：<br>    该参数用于设置Spark作业总共要用多少个Executor进程来执行。Driver在向YARN集群管理器申请资源时，YARN集群管理器会尽可能按照你的设置来在<br>    集群的各个工作节点上，启动相应数量的Executor进程。这个参数非常之重要，如果不设置的话，默认只会给你启动少量的Executor进程，此时你的<br>    Spark作业的运行速度是非常慢的。<br>参数调优建议：<br>    每个Spark作业的运行一般设置50~100个左右的Executor进程比较合适，设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；<br>    设置的太多的话，大部分队列可能无法给予充分的资源。<br>executor-memory<br>参数说明：<br>    该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联。<br>参数调优建议：<br>    每个Executor进程的内存设置4G~8G较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列<br>    的最大内存限制是多少，num-executors乘以executor-memory，是不能超过队列的最大内存量的。此外，如果你是跟团队里其他人共享这个资源队列，<br>    那么申请的内存量最好不要超过资源队列最大总内存的1/3~1/2，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行。<br>executor-cores<br>参数说明：<br>    该参数用于设置每个Executor进程的CPU core数量。这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个<br>    task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程。<br>参数调优建议：<br>    Executor的CPU core数量设置为2~4个较为合适。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的<br>    Executor数量，来决定每个Executor进程可以分配到几个CPU core。同样建议，如果是跟他人共享这个队列，那么num-executors <em> executor-cores不要超过<br>    队列总CPU core的1/3~1/2左右比较合适，也是避免影响其他同学的作业运行。<br>driver-memory<br>参数说明：<br>    该参数用于设置Driver进程的内存。<br>参数调优建议：<br>    Driver的内存通常来说不设置，或者设置1G左右应该就够了。唯一需要注意的一点是，如果需要使用collect算子将RDD的数据全部拉取到Driver上进行处理，<br>    那么必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。<br>spark.default.parallelism<br>参数说明：<br>    该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。<br>参数调优建议：<br>    Spark作业的默认task数量为500~1000个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量<br>    来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会<br>    导致你前面设置好的Executor的参数都前功尽弃。试想一下，无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的<br>    Executor进程可能根本就没有task执行，也就是白白浪费了资源！因此Spark官网建议的设置原则是，设置该参数为num-executors </em> executor-cores的2~3倍<br>    较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。<br>spark.storage.memoryFraction<br>参数说明：<br>    该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。也就是说，默认Executor 60%的内存，可以用来保存持久化的RDD数据。根据你选择<br>    的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。<br>参数调优建议：<br>    如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只<br>    能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现<br>    作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。<br>spark.shuffle.memoryFraction<br>参数说明：<br>    该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor<br>    默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时<br>    就会极大地降低性能。<br>参数调优建议：<br>    如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多<br>    时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低<br>    这个参数的值。<br>资源参数的调优，没有一个固定的值，需要根据自己的实际情况（包括Spark作业中的shuffle操作数量、RDD持久化操作数量以及spark web ui中显示的作业gc情况），合理地设置上述参数。</p>
<p>资源参数参考示例<br>以下是一份spark-submit命令的示例，大家可以参考一下，并根据自己的实际情况进行调节：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">./bin/spark-submit \</div><div class="line">  --master yarn-cluster \</div><div class="line">  --num-executors 100 \</div><div class="line">  --executor-memory 6G \</div><div class="line">  --executor-cores 4 \</div><div class="line">  --driver-memory 1G \</div><div class="line">  --conf spark.default.parallelism=1000 \</div><div class="line">  --conf spark.storage.memoryFraction=0.5 \</div><div class="line">  --conf spark.shuffle.memoryFraction=0.3 \</div></pre></td></tr></table></figure></p>
</div><div class="tags"><a href="/tags/Spark/">Spark</a></div><div class="post-nav"><a class="pre" href="/2017/08/10/Spark在yarn中的资源申请与分配调研/">Spark在yarn中的资源申请与分配</a><a class="next" href="/2017/08/07/spark在yarn中运行jdk8/">hive运行时container内存溢出错误以及解决方法</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Jupyter/" style="font-size: 15px;">Jupyter</a> <a href="/tags/Github/" style="font-size: 15px;">Github</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/Mechine-Learning/" style="font-size: 15px;">Mechine Learning</a> <a href="/tags/Decision-Tree/" style="font-size: 15px;">Decision Tree</a> <a href="/tags/数据挖掘/" style="font-size: 15px;">数据挖掘</a> <a href="/tags/URL解析/" style="font-size: 15px;">URL解析</a> <a href="/tags/Scala/" style="font-size: 15px;">Scala</a> <a href="/tags/数据清洗/" style="font-size: 15px;">数据清洗</a> <a href="/tags/URL，数据挖掘/" style="font-size: 15px;">URL，数据挖掘</a> <a href="/tags/Ubuntu/" style="font-size: 15px;">Ubuntu</a> <a href="/tags/Anaconda/" style="font-size: 15px;">Anaconda</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/Pyspark/" style="font-size: 15px;">Pyspark</a> <a href="/tags/Windows/" style="font-size: 15px;">Windows</a> <a href="/tags/Xgboost/" style="font-size: 15px;">Xgboost</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/hdfs/" style="font-size: 15px;">hdfs</a> <a href="/tags/DeepLearning/" style="font-size: 15px;">DeepLearning</a> <a href="/tags/Word2vec/" style="font-size: 15px;">Word2vec</a> <a href="/tags/神经网络/" style="font-size: 15px;">神经网络</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/Yarn/" style="font-size: 15px;">Yarn</a> <a href="/tags/机器学习，不平衡数据/" style="font-size: 15px;">机器学习，不平衡数据</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/05/22/Mechine Learning 非平衡数据处理方式与评估/">Mechine Learning 非平衡数据处理方式总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/09/URL挖掘微信QQ账号实例说明/">URL挖掘微信/QQ账号并关联Hive入库实例</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/29/URL提取互联网账号初步解析/">URL提取互联网账号初步解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/18/URL提取Email之后的数据清洗 /">URL提取Email之后的数据清洗</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/11/spark中读取hdfs文件/">spark中读取hdfs文件的几个问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/20/Hive数据倾斜问题/">Hive数据倾斜问题以及解决方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/02/word2vec入门/">DeepLearning——Word2vec笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/02/神经网络与深度学习阅读笔记/">神经网络与深度学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/28/Ubuntu（16.04)  anaconda安装tensorflow/">Ubuntu（16.04)  anaconda安装tensorflow</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/21/install xgboost in Anaconda Python (Windows platform)/">install xgboost in Anaconda Python (Windows platform)</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.csdn.net/" title="CSDN" target="_blank">CSDN</a><ul></ul><a href="http://spark.apache.org/docs/latest/" title="Spark" target="_blank">Spark</a><ul></ul><a href="https://stackoverflow.com/questions" title="stackoverflow" target="_blank">stackoverflow</a><ul></ul><a href="https://zh.wikipedia.org/" title="Wiki" target="_blank">Wiki</a><ul></ul><a href="https://tech.meituan.com/archives" title="美团点评技术团队" target="_blank">美团点评技术团队</a><ul></ul><a href="http://data.qq.com/blog" title="腾讯大数据" target="_blank">腾讯大数据</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">CaoK' Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>