<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="2017.6 CS硕士毕业,目前就职于中国电信IT研发中心大数据部门"><title>Spark在yarn中的资源申请与分配 | CaoK' Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Spark在yarn中的资源申请与分配</h1><a id="logo" href="/.">CaoK' Blog</a><p class="description">But you didn't</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Spark在yarn中的资源申请与分配</h1><div class="post-meta">Aug 10, 2017</div><div class="post-content"><p>本文解决遇到的以下问题：<br><strong><em>spark作业提交到yarn的时候，如果用户所在队列本来有500executor的权限，但是他跑一个简单的程序根本不需要这么多的资源，只需要200个核就足够了，那他如果申请了400个核的话，是否需要全部分配给他？</em></strong></p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a><strong>前言</strong></h1><p>目前我们所有的spark程序的分配都是靠参数设置固定的Executor数量进行资源预分配的，如果用户op在yarn的资源队列里可以申请到200个资源，那它就算跑占用资源很少的程序也能申请到200个核，这是不合理的！<br>比如简单跑如下SparkPi程序，申请20个核：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./bin/spark-submit --<span class="class"><span class="keyword">class</span> <span class="title">org</span>.<span class="title">apache</span>.<span class="title">spark</span>.<span class="title">examples</span>.<span class="title">SparkPi</span> <span class="title">--master</span> <span class="title">yarn-client</span> <span class="title">--num-executors</span> 20 <span class="title">lib/spark-examples-1</span>.6.2<span class="title">-hadoop2</span>.6.0.<span class="title">jar</span></span></div></pre></td></tr></table></figure></p>
<p>yarn中资源占用情况如下：<br><img src="https://i.imgur.com/7qyq9a9.png" alt=""><br>可以看到，我就跑了一个SparkPi啊，竟然用了43G的内存，这样很不合理！</p>
<h1 id="总述"><a href="#总述" class="headerlink" title="总述"></a><strong>总述</strong></h1><p>Spark在yarn集群上运行的时候，一方面默认通过num-executors参数设置固定的Executor数量，每个application会独占所有预分配的资源直到整个生命周期的结束。Spark1.2后开始引入动态资源分配（Dynamic Resource Allocation）机制，支持资源弹性分配。</p>
<p>对于已知的业务负载，使用固定的集群资源配置是相对容易的；对于未知的业务负载，使用动态的集群资源分配方式可以满足负载的动态变化，这样集群的资源利用和业务负载的处理效率都会更加灵活。</p>
<p>动态资源分配测试在Spark1.2仅支持Yarn模式，从Spark1.6开始，支持standalone、Yarn、Mesos.这个特性默认是禁用的。</p>
<h1 id="动态资源分配的思想"><a href="#动态资源分配的思想" class="headerlink" title="动态资源分配的思想"></a><strong>动态资源分配的思想</strong></h1><p>简单来说，就是基于负载来动态调节Spark应用的资源占用，你的应用会在资源空闲的时候将其释放给集群，而后续用到的时候再重新申请。</p>
<h2 id="动态资源分配策略"><a href="#动态资源分配策略" class="headerlink" title="动态资源分配策略"></a><strong>动态资源分配策略</strong></h2><p>其实没有一个固定的方法可以预测一个executor后续是否马上会被分配去执行任务，或者一个新分配的执行器实际上是空闲的，所以我们需要一些试探性的方法，来决定是否申请或移除一个执行器。策略分为请求策略与移除策略：</p>
<h2 id="请求策略"><a href="#请求策略" class="headerlink" title="请求策略"></a><strong>请求策略</strong></h2><p>开启动态分配策略后，application会在task因没有足够资源被挂起的时候去动态申请资源，这种情况意味着该application现有的executor无法满足所有task并行运行。spark一轮一轮的申请资源，当有task挂起或等待spark.dynamicAllocation.schedulerBacklogTimeout(默认1s)时间的时候，会开始动态资源分配；之后会每隔spark.dynamicAllocation.sustainedSchedulerBacklogTimeout(默认1s)时间申请一次，直到申请到足够的资源。每次申请的资源量是指数增长的，即1,2,4,8等。<br>之所以采用指数增长，出于两方面考虑：其一，开始申请的少是考虑到可能application会马上得到满足；其次要成倍增加，是为了如果application需要很多资源，而该方式可以在很少次数的申请之后得到满足。<br>（这段指数增长的策略可以根据实际情况通过修改源码来修改）</p>
<h2 id="资源回收策略"><a href="#资源回收策略" class="headerlink" title="资源回收策略"></a><strong>资源回收策略</strong></h2><p>当application的executor空闲时间超过spark.dynamicAllocation.executorIdleTimeout（默认60s）后，就会被回收。</p>
<h1 id="配置思路"><a href="#配置思路" class="headerlink" title="配置思路"></a><strong>配置思路</strong></h1><h2 id="启动-external-shuffle-service"><a href="#启动-external-shuffle-service" class="headerlink" title="启动 external shuffle service"></a><strong>启动 external shuffle service</strong></h2><p>要使用这一特性有两个前提条件。首先，你的应用必须设置 spark.dynamicAllocation.enabled 为 true。其次，你必须在每个节点上启动一个外部混洗服务（external shuffle service），并在你的应用中将 spark.shuffle.service.enabled 设为true。外部混洗服务的目的就是为了在删除执行器的时候，能够保留其输出的混洗文件（本文后续有更详细的描述）。启用外部混洗的方式在各个集群管理器上各不相同：<br>在Spark独立部署的集群中，你只需要在worker启动前设置 spark.shuffle.server.enabled 为true即可。<br>在YARN模式下，混洗服务需要按以下步骤在各个NodeManager上启动：</p>
<ol>
<li>首先按照YARN profile 构建Spark。如果你已经有打好包的Spark，可以忽略这一步。</li>
<li>找到 spark–yarn-shuffle.jar。如果你是自定义编译，其位置应该在 ${SPARK_HOME}/network/yarn/target/scala-，否则应该可以在 lib 目录下找到这个jar包。</li>
<li>将该jar包添加到NodeManager的classpath路径中。</li>
<li>配置各个节点上的yarn-site.xml，将 spark_shuffle 添加到 yarn.nodemanager.aux-services 中，然后将 yarn.nodemanager.aux-services.spark_shuffle.class 设为 org.apache.spark.network.yarn.YarnShuffleService，并将 spark.shuffle.service.enabled 设为 true。</li>
<li>最后重启各节点上的NodeManager。</li>
<li>所有相关的配置都是可选的，并且都在 spark.dynamicAllocation. 和 spark.shuffle.service. 命名空间下。更详细请参考：<a href="http://spark.apache.org/docs/latest/configuration.html#dynamic-allocation" target="_blank" rel="external">configurations page</a></li>
</ol>
<h1 id="外部混洗服务external-shuffle-service"><a href="#外部混洗服务external-shuffle-service" class="headerlink" title="外部混洗服务external shuffle service"></a><strong>外部混洗服务external shuffle service</strong></h1><p>非动态分配模式下，执行器可能的退出原因有执行失败或者相关Spark应用已经退出。不管是哪种原因，执行器的所有状态都已经不再需要，可以丢弃掉。但在动态分配的情形下，执行器有可能在Spark应用运行期间被移除。这时候，如果Spark应用尝试去访问该执行器存储的状态，就必须重算这一部分数据。因此，Spark需要一种机制，能够优雅地关闭执行器，同时还保留其状态数据。</p>
<p>这种需求对于混洗操作尤其重要。混洗过程中，Spark执行器首先将map输出写到本地磁盘，同时执行器本身又是一个文件服务器，这样其他执行器就能够通过该执行器获得对应的map结果数据。一旦有某些任务执行时间过长，动态分配有可能在混洗结束前移除任务异常的执行器，而这些被移除的执行器对应的数据将会被重新计算，但这些重算其实是不必要的。</p>
<p>要解决这一问题，就需要用到一个外部混洗服务（external shuffle service），该服务在Spark 1.2引入。该服务在每个节点上都会启动一个不依赖于任何Spark应用或执行器的独立进程。一旦该服务启用，Spark执行器不再从各个执行器上获取shuffle文件，转而从这个service获取。这意味着，任何执行器输出的混洗状态数据都可能存留时间比对应的执行器进程还长。</p>
<p>除了混洗文件之外，执行器也会在磁盘或者内存中缓存数。一旦执行器被移除，其缓存数据将无法访问。这个问题目前还没有解决。或许在未来的版本中，可能会采用外部混洗服务类似的方法，将缓存数据保存在堆外存储中以解决这一问题。</p>
<p><strong><strong>配置说明</strong></strong><br>配置文件：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$SPARK_HOME</span>/conf/spark-defaults.conf</div><div class="line"><span class="variable">$HADOOP_HOME</span>/conf/yarn-site.xml</div></pre></td></tr></table></figure></p>
<p><strong><em>Spark配置说明</em></strong><br>在spark-defaults.conf 中添加<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">spark.shuffle.service.enabled <span class="literal">true</span>   <span class="comment"># 开启外部shuffle服务，开启这个服务可以保护executor的shuffle文件，安全移除executor，在Yarn模式下这个shuffle服务以org.apache.spark.yarn.network.YarnShuffleService实现</span></div><div class="line">spark.shuffle.service.port 7337 <span class="comment"># Shuffle Service服务端口，必须和yarn-site中的一致</span></div><div class="line">spark.dynamicAllocation.enabled <span class="literal">true</span>  <span class="comment"># 开启动态资源分配</span></div><div class="line">spark.dynamicAllocation.minExecutors 1  <span class="comment"># 每个Application最小分配的executor数</span></div><div class="line">spark.dynamicAllocation.maxExecutors 30  <span class="comment"># 每个Application最大并发分配的executor数</span></div><div class="line">spark.dynamicAllocation.schedulerBacklogTimeout 1s <span class="comment"># 任务待时间（超时便申请新资源)默认60秒</span></div><div class="line">spark.dynamicAllocation.sustainedSchedulerBacklogTimeout 5s <span class="comment">#  再次请求等待时间，默认60秒</span></div><div class="line">spark.dynamicAllocation.executorIdleTimeout <span class="comment"># executor闲置时间（超过释放资源）默认600秒</span></div></pre></td></tr></table></figure></p>
<p><strong><em>yarn的配置</em></strong><br>添加相应的jar包spark–yarn-shuffle.jar<br>如果是自己编译的spark，可以在$SPARK_HOME/network/yarn/target/scala-下面找到<br>是预编译的，直接在$SPARK_HOME/lib/下面找到<br>找到jar包后，将其添加到每个nodemanager的classpath下面(或者直接放到yarn的lib目录中,${HADOOP_HOME}/share/hadoop/yarn/lib/)</p>
<p>配置yarn-site.xml文件<br>在所有节点的yarn-site.xml中，为yarn.nodemanager.aux-services配置项新增spark_shuffle这个值（注意是新增，在原有value的基础上逗号分隔新增即可）<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#yarn-site.xml</span></div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;spark.shuffle.service.enabled&lt;/name&gt;</div><div class="line">  &lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</div><div class="line">  &lt;value&gt;mapreduce_shuffle,spark_shuffle&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;yarn.nodemanager.aux-services.spark_shuffle.class&lt;/name&gt;</div><div class="line">  &lt;value&gt;org.apache.spark.network.yarn.YarnShuffleService&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure></p>
<p>重启所有的节点<br><strong>注意</strong><br>当开启了动态资源分配（spark.dynamicAllocation.enabled），num-executor选项将不再兼容，如果设置了num-executor，那么动态资源分配将被关闭</p>
</div><div class="tags"><a href="/tags/Spark/">Spark</a><a href="/tags/Yarn/">Yarn</a></div><div class="post-nav"><a class="pre" href="/2017/09/14/install pyspark on windows/">在windows上面安装并用jupyter运行pyspark</a><a class="next" href="/2017/08/08/sparksubmit优化/">spark submit参数说明与调优</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/Github/" style="font-size: 15px;">Github</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/Mechine-Learning/" style="font-size: 15px;">Mechine Learning</a> <a href="/tags/Decision-Tree/" style="font-size: 15px;">Decision Tree</a> <a href="/tags/数据挖掘/" style="font-size: 15px;">数据挖掘</a> <a href="/tags/URL解析/" style="font-size: 15px;">URL解析</a> <a href="/tags/Scala/" style="font-size: 15px;">Scala</a> <a href="/tags/数据清洗/" style="font-size: 15px;">数据清洗</a> <a href="/tags/URL，数据挖掘/" style="font-size: 15px;">URL，数据挖掘</a> <a href="/tags/Ubuntu/" style="font-size: 15px;">Ubuntu</a> <a href="/tags/Anaconda/" style="font-size: 15px;">Anaconda</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/Jupyter/" style="font-size: 15px;">Jupyter</a> <a href="/tags/Pyspark/" style="font-size: 15px;">Pyspark</a> <a href="/tags/Windows/" style="font-size: 15px;">Windows</a> <a href="/tags/Xgboost/" style="font-size: 15px;">Xgboost</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/hdfs/" style="font-size: 15px;">hdfs</a> <a href="/tags/DeepLearning/" style="font-size: 15px;">DeepLearning</a> <a href="/tags/Word2vec/" style="font-size: 15px;">Word2vec</a> <a href="/tags/神经网络/" style="font-size: 15px;">神经网络</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/Yarn/" style="font-size: 15px;">Yarn</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/03/09/URL挖掘微信QQ账号实例说明/">URL挖掘微信/QQ账号并关联Hive入库实例</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/29/URL提取互联网账号初步解析/">URL提取互联网账号初步解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/18/URL提取Email之后的数据清洗 /">URL提取Email之后的数据清洗</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/11/spark中读取hdfs文件/">spark中读取hdfs文件的几个问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/20/Hive数据倾斜问题/">Hive数据倾斜问题以及解决方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/02/word2vec入门/">DeepLearning——Word2vec笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/02/神经网络与深度学习阅读笔记/">神经网络与深度学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/28/Ubuntu（16.04)  anaconda安装tensorflow/">Ubuntu（16.04)  anaconda安装tensorflow</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/21/install xgboost in Anaconda Python (Windows platform)/">install xgboost in Anaconda Python (Windows platform)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/14/install pyspark on windows/">在windows上面安装并用jupyter运行pyspark</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.csdn.net/" title="CSDN" target="_blank">CSDN</a><ul></ul><a href="http://spark.apache.org/docs/latest/" title="Spark" target="_blank">Spark</a><ul></ul><a href="https://stackoverflow.com/questions" title="stackoverflow" target="_blank">stackoverflow</a><ul></ul><a href="https://zh.wikipedia.org/" title="Wiki" target="_blank">Wiki</a><ul></ul><a href="https://tech.meituan.com/archives" title="美团点评技术团队" target="_blank">美团点评技术团队</a><ul></ul><a href="http://data.qq.com/blog" title="腾讯大数据" target="_blank">腾讯大数据</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">CaoK' Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>