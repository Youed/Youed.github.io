<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="2017.6 CS硕士毕业,目前就职于中国电信IT研发中心大数据部门"><title>atec初赛第九名小结 | CaoK' Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">atec初赛第九名小结</h1><a id="logo" href="/.">CaoK' Blog</a><p class="description">But you didn't</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">atec初赛第九名小结</h1><div class="post-meta">Jul 12, 2018</div><div class="post-content"><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>蚂蚁开发者大赛中，我们组选择风险大脑-支付风险识别这个题目。<br>下面将通过赛题简介、评价指标分析、数据分析、模型设计以及初赛经验总结这几个方面简单的介绍一下初赛的成果，为复赛做准备。</p>
<h2 id="赛题简介"><a href="#赛题简介" class="headerlink" title="赛题简介"></a>赛题简介</h2><p>风控大脑这个题的背景来源于真实的安全风控业务。这个问题的本质是，如果发生了交易风险，我们如何用大量的历史数据去发现异常交易，我们需要根据已有的特征去判别一笔交易是否存在风险。</p>
<p>这样的风控问题，有如下的四个特点：</p>
<ol>
<li><p><strong>样本失衡</strong>。99.99%的交易都是好人，真正产生案件的交易是非常少的。</p>
</li>
<li><p><strong>数据海量</strong>。风控采集非常非常多的数据，这些特征不一定是有用的</p>
</li>
<li><p><strong>攻防激烈</strong>。坏人会根据被拒绝的交易不断改变提交的参数，试探系统背后的规则策略。</p>
</li>
</ol>
<h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><p><strong>评价指标公式</strong><br>若给定一个临界值，可以根据预测的概率值算出预测的离散值，再和真实结果比对，计算出混淆矩阵。根据混淆矩阵的值可以算出FPR（False Positives rate）和TPR（True Positives Rate），即给定人工给定一个阈值，可以算出一个FPR和对应的TPR若穷举出多个阈值则可以算出多个FPR和TPR，连线即为ROC曲线。若穷举出多个阈值则可以算出多个FPR和TPR，连线即为ROC曲线。<img src="https://upload-images.jianshu.io/upload_images/12292185-9c04796801e6fe41.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="ROC.png"></p>
<p>定义并计算在不同打扰率下对应的覆盖率<br>TPR1：当FPR等于0.001时的TPR<br>TPR2：当FPR等于0.005时的TPR<br>TPR3：当FPR等于0.01时的TPR<br>模型成绩 score= 0.4 <em> TPR1 + 0.3 </em> TPR2 + 0.3 * TPR3</p>
<p><strong>评价指标分析</strong><br>FRP 表示正常交易被误判为异常交易/实际正常交易的比重（假正率，这里的label 1为异常交易，但是在样本中表示正，0为正常交易，但在样本中表示负）<br>TPR 表示正确预测的异常样本/实际异常交易的比重（真正率）</p>
<p>在正常交易被误判的比重为0.001时，准确捕获的异常交易的比重要尽可能大，这样TPR1的值才会尽可能大。同理，下面的TPR2,TPR3也是如此。比赛选用这个指标而不是准确率、覆盖率和召回率是因为在样本分布不平衡的情况下，ROC曲线依旧可以很好的衡量模型能力。<br><img src="https://upload-images.jianshu.io/upload_images/12292185-db73068bef2e21c7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="强学习器的ROC曲线"></p>
<h1 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h1><h2 id="一、简单数据分析"><a href="#一、简单数据分析" class="headerlink" title="一、简单数据分析"></a>一、简单数据分析</h2><p>目前来看，这是一个分类任务。我们需要根据特征集合，判定某个交易是安全交易（标签为0）还是是灰色交易（标签为1），训练集中标签为-1表示不确定。后期可以用到，前期先使用带标签的进行分析。 </p>
<p>一共有994,731条训练数据，包含了994731个不同的id，因此这个id应该是交易id，在这个题目中我们不需要针对特定用户分析行为模式，只需要简单的观察群体交易特征即可。</p>
<p>对于需要验证的标签，一共有三种，分别是0（正常）,1（异常），-1（未知中断）。其中98.3%的用户的标签是0，1.21%的用户是1,0.48%的用户标签是-1。<br><img src="https://upload-images.jianshu.io/upload_images/12292185-a226c2c90f1abe71.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="样本分布图"></p>
<p>训练样本包含了62天的数据信息,时间区间从20170905到20171105，平均每天的记录规模是16000左右。</p>
<h2 id="二、标签为-1的样本的处理"><a href="#二、标签为-1的样本的处理" class="headerlink" title="二、标签为-1的样本的处理"></a>二、标签为-1的样本的处理</h2><p><strong>-1是未知标签，因此在这个问题上，合理使用这些样本是一个加分关键点。</strong></p>
<ol>
<li>完全不考虑label为-1的情况（可以作为baseline）</li>
<li>将label为-1的全部标记为1，放入训练集.因为这些因为异常被中断的交易是蚂蚁风控系统认为风险比较大的交易，因此可能蕴含着异常交易的特征，可以用于补充label 1样本太少的问题。</li>
<li>使用机器学习算法对label为-1样本进行预测学习，将被大概率预测为1的样本标记为1，放入训练集中。</li>
</ol>
<p>在初赛阶段，我们发现第二种处理方式的效果要优于另外两种方式。</p>
<h2 id="三、-样本倾斜问题"><a href="#三、-样本倾斜问题" class="headerlink" title="三、 样本倾斜问题"></a>三、 样本倾斜问题</h2><p>正负样本的数量相差两个数量级，样本不均衡。</p>
<ol>
<li>采用上采样（Oversampling）和下采样（Undersampling），上采样是把小众类复制多份，下采样是从大众类中剔除一些样本，或者说只从大众类中选取部分样本。</li>
<li>加权损失函数：在模型训练的损失函数中，为预测错误的损失值设置权重</li>
<li>不采取任何的措施，直接进行分类。</li>
</ol>
<p>在初赛阶段，我们发现使用第三种方式的处理结果要优于其余两种方式。</p>
<h2 id="四、特征分析"><a href="#四、特征分析" class="headerlink" title="四、特征分析"></a>四、特征分析</h2><p>赛方一共提供了298个特征列，在使用全部的特征进行模型训练时，发现模型指标只能在0.30左右，陷入局部最优。因此需要对特征列进行分析，选择真正对结果有帮助的特征列。因为特征列的缺失情况不一，为避免<strong>缺失值填充</strong>对特征选择的影响，我们先进行了特征选择。选择的主要依据有</p>
<ol>
<li>特征的缺失率不能太大。若大部分样本都缺失，则特征无用。</li>
<li>训练集和测试集的特征分布一致，不能有太大的偏差。否则建立的模型不具备泛化能力。</li>
<li>标签在不同的特征值上的分布具有差异性</li>
<li>通过gdbt算法训练出的模型选择重要特征</li>
</ol>
<h3 id="4-1-特征缺失率"><a href="#4-1-特征缺失率" class="headerlink" title="4.1 特征缺失率"></a>4.1 特征缺失率</h3><p>对特征的缺失情况进行分析，得到下面的缺失值和特征数表格。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12292185-44f65fe4c64830e7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="缺失值-特征数表格.png"></p>
<p>可以发现虽然一共有298个特征列，但是数据的缺失数量只有13个不同的值，这是否意味着，特征之间有关联（暂时不知道复赛数据的猜测）？可以看到有12个特征他们的缺失情况是925781，大部分的样本都没有数据。只有139个特征的缺失率是低于20%。<br>对于这样的数据分布，我们尝试了不同的特征删除策略：删除缺失率大于20%，30%，40%，50%等等。<br>同时观察测试集的数据，我们发现对于相同的特征，训练集和测试集的缺失情况不尽相同，因此通过对比之后，删除训练集和测试集缺失率相差有点大的列。</p>
<h3 id="4-2-训练集和测试集的特征分布一致"><a href="#4-2-训练集和测试集的特征分布一致" class="headerlink" title="4.2 训练集和测试集的特征分布一致"></a>4.2 训练集和测试集的特征分布一致</h3><p>正常的情况下，训练集和测试集的特征分布应该一致，这样根据训练集训练得到的模型才对测试集适用。一致的分布意味着，取值范围一致，概率密度核kde分布曲线类似。</p>
<p>以特征f15为例，在训练集和测试集上都只有三个值，且在这三个值上的kde曲线基本重叠。<img src="https://upload-images.jianshu.io/upload_images/12292185-3a406fc5abf8c644.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="f15特征在训练集上的分布、在测试集上的分布、训练集和测试集分布对比"></p>
<p>而f21特征在训练集上是一个多值分布，而在测试集上是二值分布，通过最后一张对比图可以明显的看出分布的异常。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12292185-45fd30172f4fdf4d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="f21特征在训练集上的分布、在测试集上的分布、训练集和测试集分布对比"> </p>
<p>f54虽然在训练集和测试集上都是多值分布，但是训练集分布的范围是[0,100]，而测试机的范围在[0,300]。因此这样的特征不具备训练的意义。<br><img src="https://upload-images.jianshu.io/upload_images/12292185-7021c5c33a5b172f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="f54特征在训练集上的分布、在测试集上的分布、训练集和测试集分布对比"></p>
<h3 id="4-3-特征具有区别标签的能力"><a href="#4-3-特征具有区别标签的能力" class="headerlink" title="4.3 特征具有区别标签的能力"></a>4.3 特征具有区别标签的能力</h3><p>对于特定的特征，如果样本标签在各值上的分布没有明显的区别，那么这个特征对于最终的预测能起到的作用很小。相反，如果某个特征值上异常交易占比特别高，那么当新样本出现这个特征值时，系统就会引起警觉。常规的方式有</p>
<ol>
<li>通过训练集特征与label的pearson相关性选择特征 </li>
<li>通过观察异常交易在每个特征值上的占比情况选择特征</li>
</ol>
<p>以具有区分度的f2特征和不具备区分度的f10特征的对比。图的横坐标是特征的取值，纵坐标是异常交易，即标签为1的样本占特征值为该值的标签的比率。<br><img src="https://upload-images.jianshu.io/upload_images/12292185-1b6fc73fae3052b3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="f2特征值-异常交易占比"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/12292185-9ee347b33ac5cd14.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="f10特征值-异常交易占比"></p>
<p>f2特征在取值为2时，异常交易占比达到了0.18，而其余两个值的占比低于0.025，因此当交易的f2出现2值时，有较大的概率为异常交易。反之。f10的三个值占比都很平均，无法通过这个特征单一分析出交易是否是异常交易的概率，对标签不具有敏感性。在特征选择的时候，这样的特征最好删除。</p>
<h2 id="五、缺失值填充"><a href="#五、缺失值填充" class="headerlink" title="五、缺失值填充"></a>五、缺失值填充</h2><p>在对每个特征进行分析，然后通过实验综合考量得到训练特征之前，我们还需要做特征处理<br>缺失值填充可以分为连续值的缺失值填充和离散值的缺失值填充。连续值的缺失值填充常见的有中值填充、众数填充、均值填充以及使用randomforest等机器学习算法进行填充。缺失值的填充也有众数填充，-1填充以及使用学习算法进行填充。</p>
<p>在本题中，需要不断验证的是如下两个方面：</p>
<ol>
<li>如何划分特征是连续值还是离散值。我们通过观察每个特征的分布情况，人为的划分，然后根据赛方反馈的结果进行调整。</li>
<li>用什么方法进行填充。在现阶段我们发现对于连续值，使用中值填充的方式优于均值填充。对于离散值，则是-1填充较好。</li>
</ol>
<h1 id="模型设计"><a href="#模型设计" class="headerlink" title="模型设计"></a>模型设计</h1><p>在完成了特征分析和处理之后，进入到了最复杂的过程，模型训练。实际上，上面的-1标签的处理、数据倾斜的处理、特征选择和缺失值填充也是模型训练的有机组成部分。在实际的工作中，我们会先确定上面的部分，然后调节实验参数，得到较好的本地结果，上传系统得到评分，然后再修改特征部分，调节参数，…，一直循环这样的过程，不断分析本地结果和系统结果的得失。有时候会陷入局部最优，一直无法提升成绩，有的时候又会因为一次提升而全组欢庆。<br><img src="https://upload-images.jianshu.io/upload_images/12292185-5b01a13d8664c740.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="模型训练大致步骤"></p>
<p>模型训练大致可以用上面这张图表示。一共有四个步骤：</p>
<ol>
<li>交叉验证集的生成</li>
<li>模型选择</li>
<li>参数优化</li>
<li>模型融合</li>
</ol>
<h2 id="一、交叉验证集的生成"><a href="#一、交叉验证集的生成" class="headerlink" title="一、交叉验证集的生成"></a>一、交叉验证集的生成</h2><p>在比赛过程中，发现有同仁提出按照时间排序之后，分成五份，依次取4份作为训练集一份作为测试集进行模型训练，如此交叉验证的结果优于随机选择的5折交叉验证。</p>
<h2 id="二、模型选择"><a href="#二、模型选择" class="headerlink" title="二、模型选择"></a>二、模型选择</h2><p>分类问题的传统模型有logistics regression,SVM。目前业界常用的有集成学习方法和深度学习方法。集成学习通过融合多个独立的学习器，通过一定的策略结合可以最终形成一个强学习器。深度学习的算法依托于tensorflow框架，概念源于人工神经网络，其本质是含多隐层的多层感知器。我们对每个模型进行尝试，将结果较好的多个模型的结果进行融合，完成整个模型的训练。下面依次简单介绍每个模型运行的结果和优缺点。</p>
<h3 id="2-1-Logistics-Regression"><a href="#2-1-Logistics-Regression" class="headerlink" title="2.1 Logistics Regression"></a>2.1 Logistics Regression</h3><p>逻辑回归模型是应用最广泛的分类模型，在广告投放系统中大放异彩。因此，尽管在机器学习比赛中并没有杰出的表现，我们依旧尝试探索这个算法的效果。</p>
<p>逻辑回归算法简单易于理解，他在特征空间上寻找一个决策边界，将空间化为两个部分：正样本空间和负样本空间。如果样本在特征空间上远离决策边界，那么样本属于该部分的概率越大。逻辑回归的缺点是不适用于大规模数据的情况，因为每次迭代参数需要遍历全部的样本。</p>
<p>在本次比赛中，使用五折交叉验证的训练样本的数量达到了80万，因此单机训练该模型的时间长达1~2小时，是lightgbm模型运行时间的5倍左右。</p>
<p>在特征的预处理模块，还需要额外使用标准的归一化处理特征，避免因为量纲问题导致训练速度过慢。最终的效果是0.15左右。（数据来自李金洋）</p>
<h3 id="2-2-SVM"><a href="#2-2-SVM" class="headerlink" title="2.2 SVM"></a>2.2 SVM</h3><p>SVM是一种二分类问题模型。基本思想是找出在特征空间上间隔最大的线性分类器。SVM在处理大规模数据的时候存在训练时间长和内存需求过大的问题。在实际的实验中，发现单机只能运行1万条数据，否则会内存溢出报错。因此只能采取抽样的方式，每次抽取一万条数据，训练多个SVM学习器，实际的结果score大约在0.3左右。（数据来自范顺国）<br><img src="https://upload-images.jianshu.io/upload_images/12292185-0e04addc9d9afa12.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="SVM训练过程"></p>
<h3 id="2-3-Xgboost"><a href="#2-3-Xgboost" class="headerlink" title="2.3 Xgboost"></a>2.3 Xgboost</h3><p>Xgboost近年来在竞赛和工业界使用都非常频繁，能有效的应用到分类、回归、排序问题上。提起XGBooost的背景，则必须提到集成学习、boosting概念以及GBDT算法。集成学习是通过将多个弱学习器通过一定的策略整合之后得到的强学习器。它可以分为分为两类，一类是以随机森林为代表的bagging算法，一类是以GBDT为代表的boosting算法。bagging算法的个体学习器是不存在依赖关系的，个体学习器可以并行生成。boosting系列的则是个体学习器之间是串行生成的，每个学习器都依赖于前一个学习器的结果。GBDT是以决策树（CART）为基学习器的boosting算法，而xgboost扩展和改进了GDBT，xgboost算法更快，准确率也相对高一些，大约可以到达0.41。（数据来自范顺国）</p>
<h3 id="2-4-Lightgbm"><a href="#2-4-Lightgbm" class="headerlink" title="2.4 Lightgbm"></a>2.4 Lightgbm</h3><p>Lightgbm是微软去年推出的很好用的机器学习竞赛算法。它的本质也是集成学习的算法，这个方法中可以通过参数选择使用随机森林、GBDT或者是Goss算法。相对于传统的sklearn中的集成算法，这个算法的优点在于：</p>
<ol>
<li>传统集成算法对于CART树使用pre-sorted的算法。这是一个简单的解决方案，但是不易于优化。LightGBM 利用基于 histogram 的算法 通过将连续特征（属性）值分段为 discrete bins 来加快训练的速度并减少内存的使用。</li>
<li>大部分决策树的学习算法通过level(depth)-wise策略生长树，而lightgbm使用Leaf-wise (Best-first) 的决策树生长策略。它将选取具有最大损失的叶节点来生长。 因此在叶子结点相同的时候，leaf-wise 算法可以比 level-wise算法减少更多的损失。</li>
<li>大多数机器学习工具都无法直接支持类别特征，一般需要把类别特征转化one-hotting特征，降低了空间和时间的效率。LightGBM优化了对类别特征的支持，可以直接输入类别特征，不需要额外操作。并在决策树算法上增加了类别特征的决策规则。</li>
</ol>
<p>在实践中，我们发现lightgbm算法可以达到xgboost相同的score，但是时间开销更少。同时，因为lightgbm可以同时训练GBDT模型和随机森林模型，因此简化了写代码的时间开销。通过实际训练对比，发现使用GBDT的score要略优于使用随机森林模型。</p>
<p>LightGbm的训练参数有很多，主要的有叶子节点数num_leaves，叶子结点中含有的最少样本数min_child_samples，学习速率learning_rate以及训练循环次数num_boost_round。使用5折交叉验证，在最佳的情况下，score可以达到0.43。</p>
<h3 id="2-5-深度学习DNN"><a href="#2-5-深度学习DNN" class="headerlink" title="2.5 深度学习DNN"></a>2.5 深度学习DNN</h3><p>DNN(Deep Neural Network)神经网络模型又叫全连接神经网络，是基本的深度学习框架。DNN的基石是多层感知机，顾名思义，就是有多个隐含层的感知机。更多的层数让网络更能够刻画现实世界中的复杂情形，因而神经网络的层数直接决定了它对现实的刻画能力。<br><img src="https://upload-images.jianshu.io/upload_images/12292185-b3118363f0a7ff76.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="DNN模型示例"><br>(图片来自网络)</p>
<p>DNN模型具有超强的拟合能力，但也因此容易陷入过拟合。DNN模型多用于图像处理方面，调参比较复杂，使用起来因为无法直观感受参数变化的实际意义，因此更像黑匣子。因为参数复杂导致了训练调参的开销很大。实际运行的score和lightgbm相似。而在公司PC机上，没有GPU资源，所以在CPU上运行百万级数据的时间开销在小时级别，而lightgbm的时间开销在分钟级别上。</p>
<h2 id="三、参数优化"><a href="#三、参数优化" class="headerlink" title="三、参数优化"></a>三、参数优化</h2><p>常用的参数优化方式有两种，第一种是使用基于网格搜索grid-search的方式；第二种是基于贝叶斯优化的参数搜索方式，已有的hyperopt包就是这样的最优参数搜索包。</p>
<h3 id="grid-search参数优化"><a href="#grid-search参数优化" class="headerlink" title="grid-search参数优化"></a>grid-search参数优化</h3><p>基于grid-search的参数优化的本质是给定需要调节的参数名称以及参数值，通过遍历这个参数空间，尝试每一种参数之间的搭配，选择score最高的参数值作为返回。sklearn.model_selection中提供了ParameterGrid方法，可以对给定的参数生成遍历之后的参数组合列表，将这样的参数传入算法中，依次训练即可得到参数空间中最优的参数值。<br><img src="https://upload-images.jianshu.io/upload_images/12292185-32483ba56f049f76.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="ParameterGrid"></p>
<h3 id="hyperopt参数优化"><a href="#hyperopt参数优化" class="headerlink" title="hyperopt参数优化"></a>hyperopt参数优化</h3><p>grid-search 是全空间扫描，所以比较慢。hyperopt是一种通过贝叶斯优化（<a href="https://blog.csdn.net/cqzz513524327/article/details/72772205/" target="_blank" rel="external">贝叶斯优化简介</a>）来调整参数的工具，对于像XGBoost这种参数比较多的算法，可以用它来获取比较好的参数值。</p>
<p>hyperopt需要对每个参数指定搜索空间，而不是如grid-search中那样指定值，比如参数x在0-1区间内均匀取值，参数y在0-1之间对数取值。然后，可以指定参数优化的搜索算法，如随机搜索(对应是hyperopt.rand.suggest)和模拟退火(对应是hyperopt.anneal.suggest)，TPE算法。</p>
<h2 id="四、模型融合"><a href="#四、模型融合" class="headerlink" title="四、模型融合"></a>四、模型融合</h2><p>模型融合就是将多个模型的结果重新整理归纳，得到一个更具有泛化能力和精度的最终模型。多模型融合算法可以比单一模型算法有极为明显的效果提升。但是怎样进行有效的融合，充分发挥各个算法的长处</p>
<h3 id="4-1-均值融合"><a href="#4-1-均值融合" class="headerlink" title="4.1 均值融合"></a>4.1 均值融合</h3><p>将每个模型结果取均值得到最终的结果，这样的模型融合方式就是均值融合。这种简单的方式，实际效果很很好。通过融合多个成绩在0.40-0.43的lightgbm模型，最终的score可以达到0.4361. </p>
<h3 id="4-2-线性加权融合"><a href="#4-2-线性加权融合" class="headerlink" title="4.2 线性加权融合"></a>4.2 线性加权融合</h3><p>线性加权是最简单易用的融合算法，工程实现非常方便，只需要汇总单一模型的结果，然后按不同算法赋予不同的权重，将多个推荐算法的结果进行加权。如果每个模型的权重一致，那么就变成上面的均值融合。在多个模型设置权重时，根据每个模型的score得分分配权重。通过线性加权融合xgboost、lightgbm模型之后，score得分可以达到0.45左右。</p>
<h3 id="4-3-基于模型的加权融合"><a href="#4-3-基于模型的加权融合" class="headerlink" title="4.3 基于模型的加权融合"></a>4.3 基于模型的加权融合</h3><p>加权混合的模型有很多，除了简单的线性模型外，常用的有回归模型（Logistic Regression）、RBM（Restricted Boltzmann Machines）、GBDT（Gradient Boosted Decision Trees），这三种混合模型在推荐算法竞赛中大放异彩，在2009年结束的Netflix百万美元推荐竞赛中，优胜队伍将充分运用和多种加权混合模型的优势，组合后的算法推荐精度非常高。获胜队的Yehuda Koren在论文The BellKor Solution to the Netflix Grand Prize中对此有非常详细的介绍。<br>在初赛中我们使用了DNN模型进行融合，<br>在未来的复赛中，我们会尝试使用DNN模型、logistic regression模型和GBDT模型进行融合。</p>
<h3 id="4-4-Blending交叉融合"><a href="#4-4-Blending交叉融合" class="headerlink" title="4.4 Blending交叉融合"></a>4.4 Blending交叉融合</h3><p>交叉融合常被称为Blending方法，通常情况下适用于推荐的应用场景，其思路是在推荐结果中，穿插不同推荐模型的结果，以确保结果的多样性。这种方式将不同算法的结果组合在一起推荐给用户。</p>
<p>因为每个模型都有自己的应用倾向，为了避免单模型导致的陷入局部最优，我们也采用了blending方法将多个模型的结果切分，然后“拼凑”成一份结果。</p>
<h4 id="4-5-最终采用的策略"><a href="#4-5-最终采用的策略" class="headerlink" title="4.5 最终采用的策略"></a>4.5 最终采用的策略</h4><p>在初赛排名第9的模型中，我们采用的融合策略如下图所示，通过多种融合策略，最终得到0.4514。<br><figure class="highlight livescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">graph TD</div><div class="line">    A<span class="function"><span class="params">(特征集合F1)</span> --&gt;</span>B(Xgboost模型)</div><div class="line">    A<span class="function"> --&gt;</span>C(Lightgbm模型)</div><div class="line">    B<span class="function"> --&gt;</span>D(DNN加权融合模型)</div><div class="line">    C<span class="function"> --&gt;</span>D</div><div class="line">    E<span class="function"><span class="params">(特征集合F2)</span>--&gt;</span>F(Lightgbm模型)</div><div class="line">    G<span class="function"><span class="params">(特征集合F3)</span>--&gt;</span>H(Lightgbm模型)</div><div class="line">    F-<span class="function">-&gt;</span>I(均值融合模型)</div><div class="line">    H-<span class="function">-&gt;</span>I</div><div class="line">    I-<span class="function">-&gt;</span>J(线性加权融合)</div><div class="line">    D-<span class="function">-&gt;</span>J</div><div class="line">    J-<span class="function">-&gt;</span>K(最终结果<span class="number">0.4514</span>)</div></pre></td></tr></table></figure></p>
<h3 id="初赛经验汇总"><a href="#初赛经验汇总" class="headerlink" title="初赛经验汇总"></a>初赛经验汇总</h3></div><div class="tags"><a href="/tags/atec/">atec</a><a href="/tags/python/">python</a></div><div class="post-nav"><a class="next" href="/2018/05/22/Mechine Learning 非平衡数据处理方式与评估/">Mechine Learning 非平衡数据处理方式总结</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Pyspark/" style="font-size: 15px;">Pyspark</a> <a href="/tags/Github/" style="font-size: 15px;">Github</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/Mechine-Learning/" style="font-size: 15px;">Mechine Learning</a> <a href="/tags/Decision-Tree/" style="font-size: 15px;">Decision Tree</a> <a href="/tags/数据挖掘/" style="font-size: 15px;">数据挖掘</a> <a href="/tags/URL解析/" style="font-size: 15px;">URL解析</a> <a href="/tags/Scala/" style="font-size: 15px;">Scala</a> <a href="/tags/数据清洗/" style="font-size: 15px;">数据清洗</a> <a href="/tags/URL，数据挖掘/" style="font-size: 15px;">URL，数据挖掘</a> <a href="/tags/Ubuntu/" style="font-size: 15px;">Ubuntu</a> <a href="/tags/Anaconda/" style="font-size: 15px;">Anaconda</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/Jupyter/" style="font-size: 15px;">Jupyter</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/Windows/" style="font-size: 15px;">Windows</a> <a href="/tags/Xgboost/" style="font-size: 15px;">Xgboost</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/hdfs/" style="font-size: 15px;">hdfs</a> <a href="/tags/DeepLearning/" style="font-size: 15px;">DeepLearning</a> <a href="/tags/Word2vec/" style="font-size: 15px;">Word2vec</a> <a href="/tags/神经网络/" style="font-size: 15px;">神经网络</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/Yarn/" style="font-size: 15px;">Yarn</a> <a href="/tags/机器学习，不平衡数据/" style="font-size: 15px;">机器学习，不平衡数据</a> <a href="/tags/atec/" style="font-size: 15px;">atec</a> <a href="/tags/python/" style="font-size: 15px;">python</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/07/12/atec初赛总结/">atec初赛第九名小结</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/22/Mechine Learning 非平衡数据处理方式与评估/">Mechine Learning 非平衡数据处理方式总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/09/URL挖掘微信QQ账号实例说明/">URL挖掘微信/QQ账号并关联Hive入库实例</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/29/URL提取互联网账号初步解析/">URL提取互联网账号初步解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/18/URL提取Email之后的数据清洗 /">URL提取Email之后的数据清洗</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/11/spark中读取hdfs文件/">spark中读取hdfs文件的几个问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/20/Hive数据倾斜问题/">Hive数据倾斜问题以及解决方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/02/word2vec入门/">DeepLearning——Word2vec笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/02/神经网络与深度学习阅读笔记/">神经网络与深度学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/28/Ubuntu（16.04)  anaconda安装tensorflow/">Ubuntu（16.04)  anaconda安装tensorflow</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.csdn.net/" title="CSDN" target="_blank">CSDN</a><ul></ul><a href="http://spark.apache.org/docs/latest/" title="Spark" target="_blank">Spark</a><ul></ul><a href="https://stackoverflow.com/questions" title="stackoverflow" target="_blank">stackoverflow</a><ul></ul><a href="https://zh.wikipedia.org/" title="Wiki" target="_blank">Wiki</a><ul></ul><a href="https://tech.meituan.com/archives" title="美团点评技术团队" target="_blank">美团点评技术团队</a><ul></ul><a href="http://data.qq.com/blog" title="腾讯大数据" target="_blank">腾讯大数据</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">CaoK' Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>