<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="2017.6 CS硕士毕业,目前就职于中国电信IT研发中心大数据部门"><title>Mechine Learning 非平衡数据处理方式总结 | CaoK' Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Mechine Learning 非平衡数据处理方式总结</h1><a id="logo" href="/.">CaoK' Blog</a><p class="description">But you didn't</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Mechine Learning 非平衡数据处理方式总结</h1><div class="post-meta">May 22, 2018</div><div class="post-content"><p>在风控等场景中正负样本比例会很不平衡，如果直接调用模型得到的结果一般不会令人很满意。在最近参加的atec比赛中就遇到了1:100的数据集。网上查了一些资料，现做下总结。<br>先看总体解决方案：<br><img src="https://i.imgur.com/I4cB82G.png" alt=""></p>
<h1 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h1><p>采样方法是通过对训练集进行处理使其从不平衡的数据集变成平衡的数据集，在大部分情况下会对最终的结果带来提升。<br>采样分为上采样（Oversampling，过采样）和下采样（Undersampling， 欠采样），上采样是把小种类复制多份，下采样是从大众类中剔除一些样本，或者说只从大众类中选取部分样本。可以直接调用<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> imblearn.ensemble <span class="keyword">import</span> BalancedBaggingClassifier,EasyEnsemble</div></pre></td></tr></table></figure></p>
<h2 id="上采样"><a href="#上采样" class="headerlink" title="上采样"></a>上采样</h2><p>上采样后的数据集中会反复出现一些样本，训练出来的模型会有一定的过拟合；<br>上采样会把小众样本复制多份，一个点会在高维空间中反复出现，<strong>这会导致一个问题，那就是运气好就能分对很多点，否则分错很多点。为了解决这一问题，可以在每次生成新数据点时加入轻微的随机扰动，</strong>经验表明这种做法非常有效，但容易重过拟合！</p>
<h2 id="下采样"><a href="#下采样" class="headerlink" title="下采样"></a>下采样</h2><p>下采样的缺点显而易见，那就是最终的训练集丢失了数据，模型只学到了总体模式的一部分。<br>第一种方法叫做<strong>EasyEnsemble</strong>，利用模型融合的方法（Ensemble）：多次下采样（放回采样，这样产生的训练集才相互独立）产生多个不同的训练集，进而训练多个不同的分类器，通过组合多个分类器的结果得到最终的结果。简单的最佳实践是建立n个模型，每个模型使用稀有类别的所有样本和丰富类别的n个不同样本。假设想要合并10个模型，那么将保留例如1000例稀有类别，并随机抽取10000例丰富类别。然后，只需将10000个案例分成10块，并训练10个不同的模型。</p>
<p>第二种方法叫做<strong>BalanceCascade</strong>，利用增量训练的思想（Boosting）：先通过一次下采样产生训练集，训练一个分类器，对于那些分类正确的大众样本不放回，然后对这个更小的大众样本下采样产生训练集，训练第二个分类器，以此类推，最终组合所有分类器的结果得到最终结果。</p>
<p>第三种方法是利用KNN试图挑选那些最具代表性的大众样本，叫做<strong>NearMiss</strong>，这类方法计算量很大</p>
<h1 id="数据合成"><a href="#数据合成" class="headerlink" title="数据合成"></a>数据合成</h1><p>数据合成方法是利用已有样本生成更多样本。<br>其中最常见的一种方法叫做<strong>SMOTE</strong>，<strong>它利用小众样本在特征空间的相似性来生成新样本。</strong></p>
<p>SMOTE为每个小众样本合成相同数量的新样本，这带来一些潜在的问题：<strong>一方面是增加了类之间重叠的可能性，另一方面是生成一些没有提供有益信息的样本。</strong>为了解决这个问题，出现两种方法：Borderline-SMOTE与ADASYN。</p>
<p><strong>Borderline-SMOT</strong>E的解决思路是寻找那些应该为之合成新样本的小众样本。即为每个小众样本计算K近邻，只为那些K近邻中有一半以上大众样本的小众样本生成新样本。直观地讲，只为那些周围大部分是大众样本的小众样本生成新样本，因为这些样本往往是边界样本。确定了为哪些小众样本生成新样本后再利用SMOTE生成新样本。</p>
<p><strong>ADASYN</strong>的解决思路是根据数据分布情况为不同小众样本生成不同数量的新样本。首先根据最终的平衡程度设定总共需要生成的新小众样本数量 G，然后为每个小众样本 xi 计算分布比例 </p>
<h1 id="加权"><a href="#加权" class="headerlink" title="加权"></a>加权</h1><p>除了采样和生成新数据等方法，我们还可以通过加权的方式来解决数据不平衡问题。<br>这种方法的难点在于设置合理的权重，实际应用中一般让各个分类间的加权损失值近似相等。当然这并不是通用法则，还是需要具体问题具体分析。 </p>
<h1 id="一分类"><a href="#一分类" class="headerlink" title="一分类"></a>一分类</h1><p>对于正负样本极不平衡的场景，我们可以换一个完全不同的角度来看待问题：把它看做一分类（One Class Learning）或异常检测（Novelty Detection）问题。这类方法的重点不在于捕捉类间的差别，而是为其中一类进行建模，经典的工作包括<strong>One-class SVM</strong>等。<br><img src="https://i.imgur.com/NkcVAqq.png" alt=""></p>
<h1 id="以正确的方式使用K-fold交叉验证"><a href="#以正确的方式使用K-fold交叉验证" class="headerlink" title="以正确的方式使用K-fold交叉验证"></a>以正确的方式使用K-fold交叉验证</h1><p>这一点很容易出错，我在开始处理atec风控比赛的时候采样了上采样：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">up_sample</span><span class="params">(df)</span>:</span></div><div class="line">    df1 = df[df[<span class="string">'label'</span>]==<span class="number">0</span>]</div><div class="line">    df2 = df[df[<span class="string">'label'</span>]==<span class="number">1</span>]</div><div class="line">    df3 = pd.concat([df2,df2,df2,df2,df2,df2,df2,df2,df2,df2,df2,df2,df2])</div><div class="line">    <span class="keyword">return</span> pd.concat([df1,df3],ignore_index=<span class="keyword">True</span>)</div></pre></td></tr></table></figure></p>
<p>但是在处理交叉验证的时候直接调用了sklearn中的train_test_split<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, <span class="number">1</span>:], df.iloc[:, :<span class="number">1</span>], test_size=<span class="number">0.25</span>,</div><div class="line">                                                    random_state=<span class="number">33</span>)</div></pre></td></tr></table></figure></p>
<p>导致在本地成绩很好提交成绩很差。本质原因下图一目了然：<br>错误做法：<br><img src="https://i.imgur.com/Qr1F695.png" alt=""><br>正确做法：<br><img src="https://i.imgur.com/vvWJNGt.png" alt=""><br>参考<a href="https://yq.aliyun.com/articles/226000" target="_blank" rel="external">https://yq.aliyun.com/articles/226000</a></p>
<h1 id="基于聚类的重抽样方法"><a href="#基于聚类的重抽样方法" class="headerlink" title="基于聚类的重抽样方法"></a>基于聚类的重抽样方法</h1><p>（1）首先分别对正负例进行K-means聚类<br>（2）聚类之后进行Oversampling等系列方法<br>举例说明，假设我们运行K-means方法分别对正负例进行了聚类，结果如下：<br>正例三个簇，个数分别为：20 ， 5, 12 负例两个簇，个数分别为：4 ，6<br>可以看出，正负例簇中个数最大的为20，所以正例其他两个簇通过oversampling都提高到20个实例，负例簇都提高到（20+20+20）/2=30 个实例。<br>最后变为，正例三个簇：20,20,20 负例两个簇：30,30<br>总结下这种基于聚类的抽样算法的优点：<br>该算法不仅可以解决类间不平衡问题，而且还能解决类内部不平衡问题。 </p>
<h1 id="适应不平衡样本的模型"><a href="#适应不平衡样本的模型" class="headerlink" title="适应不平衡样本的模型"></a>适应不平衡样本的模型</h1><p>所有之前的方法都集中在数据上，并将模型保持为固定的组件。但事实上，如果设计的模型适用于不平衡数据，则不需要重新采样数据，著名的XGBoost已经是一个很好的起点，因此设计一个适用于不平衡数据集的模型也是很有意义的。</p>
<p>通过设计一个代价函数来惩罚稀有类别的错误分类而不是分类丰富类别，可以设计出许多自然泛化为稀有类别的模型。例如，调整SVM以惩罚稀有类别的错误分类。</p>
<p>.</p>
<h1 id="如何选择"><a href="#如何选择" class="headerlink" title="如何选择"></a>如何选择</h1><p>解决数据不平衡问题的方法有很多，上面只是一些最常用的方法，而最常用的方法也有这么多种，如何根据实际问题选择合适的方法呢：</p>
<ul>
<li><p>在正负样本都非常之少的情况下，应该采用数据合成的方式；</p>
</li>
<li><p>在负样本足够多，正样本非常之少且比例及其悬殊的情况下，应该考虑一分类方法；</p>
</li>
<li><p>在正负样本都足够多且比例不是特别悬殊的情况下，应该考虑采样或者加权的方法。</p>
</li>
</ul>
<ul>
<li>采样和加权在数学上是等价的，但实际应用中效果却有差别。尤其是采样了诸如Random Forest等分类方法，训练过程会对训练集进行随机采样。在这种情况下，如果计算资源允许上采样往往要比加权好一些。</li>
</ul>
<p>另外，虽然上采样和下采样都可以使数据集变得平衡，并且在数据足够多的情况下等价，但两者也是有区别的。实际应用中，<strong>一些经验</strong>是如果计算资源足够且小众类样本足够多的情况下使用上采样，否则使用下采样，因为上采样会增加训练集的大小进而增加训练时间，同时小的训练集非常容易产生过拟合。 对于下采样，如果计算资源相对较多且有良好的并行环境，应该选Ensemble方法。 </p>
<p><strong>最后玄学的东西来了，在最终我得到atec最好的成绩方案中（0.4+），并没有采样任何不平衡数据的处理，包括模型中的class weight之类的参数。而主要是对特征做了大量处理(前面的无用功好多啊)，为什么呢？玄学啊</strong></p>
</div><div class="tags"><a href="/tags/机器学习，不平衡数据/">机器学习，不平衡数据</a></div><div class="post-nav"><a class="next" href="/2018/03/09/URL挖掘微信QQ账号实例说明/">URL挖掘微信/QQ账号并关联Hive入库实例</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Jupyter/" style="font-size: 15px;">Jupyter</a> <a href="/tags/Github/" style="font-size: 15px;">Github</a> <a href="/tags/Hive/" style="font-size: 15px;">Hive</a> <a href="/tags/Mechine-Learning/" style="font-size: 15px;">Mechine Learning</a> <a href="/tags/Decision-Tree/" style="font-size: 15px;">Decision Tree</a> <a href="/tags/数据挖掘/" style="font-size: 15px;">数据挖掘</a> <a href="/tags/URL解析/" style="font-size: 15px;">URL解析</a> <a href="/tags/Scala/" style="font-size: 15px;">Scala</a> <a href="/tags/数据清洗/" style="font-size: 15px;">数据清洗</a> <a href="/tags/URL，数据挖掘/" style="font-size: 15px;">URL，数据挖掘</a> <a href="/tags/Ubuntu/" style="font-size: 15px;">Ubuntu</a> <a href="/tags/Anaconda/" style="font-size: 15px;">Anaconda</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/Pyspark/" style="font-size: 15px;">Pyspark</a> <a href="/tags/Windows/" style="font-size: 15px;">Windows</a> <a href="/tags/Xgboost/" style="font-size: 15px;">Xgboost</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Spark/" style="font-size: 15px;">Spark</a> <a href="/tags/hdfs/" style="font-size: 15px;">hdfs</a> <a href="/tags/DeepLearning/" style="font-size: 15px;">DeepLearning</a> <a href="/tags/Word2vec/" style="font-size: 15px;">Word2vec</a> <a href="/tags/神经网络/" style="font-size: 15px;">神经网络</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/Yarn/" style="font-size: 15px;">Yarn</a> <a href="/tags/机器学习，不平衡数据/" style="font-size: 15px;">机器学习，不平衡数据</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/05/22/Mechine Learning 非平衡数据处理方式与评估/">Mechine Learning 非平衡数据处理方式总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/09/URL挖掘微信QQ账号实例说明/">URL挖掘微信/QQ账号并关联Hive入库实例</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/29/URL提取互联网账号初步解析/">URL提取互联网账号初步解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/18/URL提取Email之后的数据清洗 /">URL提取Email之后的数据清洗</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/11/spark中读取hdfs文件/">spark中读取hdfs文件的几个问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/20/Hive数据倾斜问题/">Hive数据倾斜问题以及解决方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/02/word2vec入门/">DeepLearning——Word2vec笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/02/神经网络与深度学习阅读笔记/">神经网络与深度学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/28/Ubuntu（16.04)  anaconda安装tensorflow/">Ubuntu（16.04)  anaconda安装tensorflow</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/21/install xgboost in Anaconda Python (Windows platform)/">install xgboost in Anaconda Python (Windows platform)</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.csdn.net/" title="CSDN" target="_blank">CSDN</a><ul></ul><a href="http://spark.apache.org/docs/latest/" title="Spark" target="_blank">Spark</a><ul></ul><a href="https://stackoverflow.com/questions" title="stackoverflow" target="_blank">stackoverflow</a><ul></ul><a href="https://zh.wikipedia.org/" title="Wiki" target="_blank">Wiki</a><ul></ul><a href="https://tech.meituan.com/archives" title="美团点评技术团队" target="_blank">美团点评技术团队</a><ul></ul><a href="http://data.qq.com/blog" title="腾讯大数据" target="_blank">腾讯大数据</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">CaoK' Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>